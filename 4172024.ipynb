{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7005834-e10c-41fb-8dea-02bfab5accc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lorem', 'ipsum', 'dolor', 'sit', 'amet', ',', 'consectetur', 'adipiscing', 'elit', '.', 'Sed', 'gravida', 'magna', 'magna', ',', 'sed', 'commodo', 'nulla', 'dictum', 'eu', '.', 'Nulla', 'a', 'porta', 'mauris', '.', 'Proin', 'venenatis', 'cursus', 'quam', ',', 'ut', 'tristique', 'tellus', 'tempus', 'eget', '.', 'Duis', 'vitae', 'sagittis', 'odio', '.', 'Proin', 'a', 'pharetra', 'justo', '.', 'Sed', 'gravida', 'aliquet', 'arcu', ',', 'vel', 'maximus', 'dui', 'accumsan', 'vitae', '.', 'Morbi', 'a', 'nisi', 'et', 'magna', 'luctus', 'scelerisque', '.', 'Nullam', 'bibendum', 'leo', 'in', 'massa', 'convallis', ',', 'id', 'consequat', 'tellus', 'consequat', '.', 'Nam', 'vel', 'mollis', 'sem', ',', 'viverra', 'lobortis', 'massa', '.', 'Ut', 'eleifend', 'faucibus', 'elementum', '.', 'Donec', 'bibendum', 'enim', 'vel', 'urna', 'cursus', 'ornare', '.', 'Vestibulum', 'rhoncus', 'tellus', 'vel', 'lectus', 'accumsan', 'bibendum', '.']\n"
     ]
    }
   ],
   "source": [
    "# pip install nltk\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "# an unsupervized trainable model, which means\n",
    "# it can be trained on unlabeled data \n",
    "\n",
    "text = '''Lorem ipsum dolor sit amet, \n",
    "        consectetur adipiscing elit. Sed gravida\n",
    "        magna magna, sed commodo nulla dictum eu. \n",
    "        Nulla a porta mauris. Proin venenatis \n",
    "        cursus quam, ut tristique tellus tempus eget.\n",
    "        Duis vitae sagittis odio. Proin a pharetra \n",
    "        justo. Sed gravida aliquet arcu, vel maximus\n",
    "        dui accumsan vitae. Morbi a nisi et magna \n",
    "        luctus scelerisque. Nullam bibendum leo in \n",
    "        massa convallis, id consequat tellus consequat.\n",
    "        Nam vel mollis sem, viverra lobortis massa. \n",
    "        Ut eleifend faucibus elementum. Donec bibendum \n",
    "        enim vel urna cursus ornare. Vestibulum rhoncus \n",
    "        tellus vel lectus accumsan bibendum.'''\n",
    "\n",
    "print(word_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2772348-050a-4f60-8e4d-2f7f61da8400",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\jedwa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\gutenberg.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# nltk.download('gutenberg')\n",
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09c6ab3f-a1da-4b0b-9e3b-2571a235f176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[', 'Alice', \"'\", 's', 'Adventures', 'in', ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aiw = nltk.corpus.gutenberg.words(\"carroll-alice.txt\")\n",
    "aiw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db08e743-c5c7-42e1-bd38-58bb28f2e657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'comput'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(language = 'english')\n",
    "word = 'computation'\n",
    "stemmer.stem(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e331ccb1-5e8f-4b69-b5e8-badc47eb80c6",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7ee89433-542f-46f1-a7ea-e9380879e06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fish\n"
     ]
    }
   ],
   "source": [
    "# lemmatization - finding the form of a word thats related in the dictionary.\n",
    "# The process for calculating lemmas is more complex than stemming\n",
    "# but more accurate\n",
    "# lemmatization considers context AND converts the word to \n",
    "# its \"meaningful base form\" (a lemma). Words can have multiple lemmas. \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer\n",
    "word = 'fishes'\n",
    "print(lemmatizer.lemmatize(word, word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2b06a9-a79e-4651-822b-3d8171118ef8",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ac6c3915-bbb0-4a14-8557-eb8203e3202c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "text = '''I must downgrade this to 3 stars after last bus I went on ran over 2 pedestrians and kept going.I love this bus company'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "08504eb4-c60e-4a39-b40c-e04da0ecb58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.819, 'pos': 0.181, 'compound': 0.6369}\n"
     ]
    }
   ],
   "source": [
    "sentiments = []\n",
    "sentiment = analyzer.polarity_scores(text)\n",
    "print(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "64719c16-32df-4f30-bf11-4e235267363a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'I must downgrade this to 3 stars after last bus I went on ran over 2 pedestrians and kept going.I love this bus company',\n",
       "  'compound': 0.6369,\n",
       "  'positive': 0.181,\n",
       "  'negative': 0.0,\n",
       "  'neutral': 0.819}]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiments = []\n",
    "compound = sentiment['compound']\n",
    "pos = sentiment['pos']\n",
    "neg = sentiment['neg']\n",
    "neu = sentiment['neu']\n",
    "\n",
    "sentiments.append({\n",
    "    \"text\":text,\n",
    "    \"compound\": compound,\n",
    "    \"positive\":pos,\n",
    "    \"negative\":neg,\n",
    "    \"neutral\":neu\n",
    "})\n",
    "sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37b7066-cf60-4f2b-af20-16ba8437368b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
